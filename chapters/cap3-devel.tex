\chapter{Development}\label{sec:cap3}

This chapter describes the development of the anomaly detection system, which aims to create a toolkit for anomaly detection, model training, and comparison between different models. The toolkit is designed to be modular, allowing for easy integration of new models and features.

\section{Data provided by \acs{CIEMAT}}

When a discharge experiment is performed, several data is collected from the plasma. This data is collected by sensors that measure different parameters, and stored in text files for later usage.



This project uses the discharges provided by \ac{CIEMAT}, which are organized in Campaigns. For consistent comparison, C23 is used for training and C24 is used for validation.


\section{System Design}

The anomaly detection system is composed by independent nodes. There is a central node that orchestrates the system, and several nodes that implement the anomaly detection models. Each model node works as a microservice and is responsible for training and predicting anomalies using its own algorithm. The central node is responsible for managing the data flow between the model nodes and the outlier protocol. The system design is shown in \autoref{fig:system-design}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{system-arch.png}
    \caption{Anomaly detection system design}
    \label{fig:system-design}
\end{figure}

\section{Outlier Protocol}

The outlier protocol is a custom protocol based on the OpenAPI specification. It is a simple protocol that describes how the orchestrator interacts with the model nodes, and is based on HTTP messages, which can be grouped into three main categories: \textit{health}, \textit{train}, and \textit{predict}.

The current implementation is based on offline data, and a preprocessing is required in order to transform real data to the model's accepted one. This preprocessing consists on \todo{acotar} the discharge (delete everything before the beginning of the experiment, as sensors might be activated from before), and to \todo{remuestrear} data to a constant rate (1 or 2 ms accepted).

\subsection{Health}

Models must implement the \texttt{/health} endpoint in order to be visible to the orchestrator. The orchestrator will send a \texttt{GET} message at a variable time. If the model does not answer, orchestrator must consider the model as unavailable, and data must not be sent to this model.\ \autoref{fig:health-message} shows the sequence diagram of the health message and its response. This message also includes the model name, uptime, and last training time.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{health.png}
    \caption{Health message sequence diagram}
    \label{fig:health-message}
\end{figure}

\subsection{Train} 

This category describes how models will be trained in order to acquire data for disruption prediction. 

Protocol begins with a \texttt{post} message to the \texttt{/train} model endpoint that contains the number of discharges that will be sent to the models. Models that want to accept the training, answer with a 200 response. Then the orchestrator sends, one by one, the training discharges. After a discharge is received, models must acknowledge it. When all discharges are sent, models shall start the training.

When the training is done, models must inform the orchestrator, as shown in \autoref{fig:train-message}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{train.png}
    \caption{Train message sequence diagram}
    \label{fig:train-message}
\end{figure}

\subsection{Predict}
\todo[inline]{Actualizar la figura de predict. En el outlier protocol no estÃ¡n puestas las features que se deben enviar.
\href{https://github.com/outlierClassifier/outlier_protocol/issues/3}{GH issue 3}}

The \texttt{predict} message is sent by the orchestrator to the alive models. It is a \texttt{POST} message to the \texttt{/predict} model endpoint and simulates online data. For this reason, models must send a prediction per window and the features that have been taken into account for the decision. Models must also report a \textit{justification} value, which is the confidence of that window to belong to a class.

\missingfigure{Prediction response message sequence diagram}

\section{Outlier Orchestrator}\label{sec:orchestrator}

The outlier orchestrator is the central node of the anomaly detection system. It is responsible for managing the data flow between the model nodes, using the outlier protocol to communicate with them.

The orchestrator consists on a frontend and a backend. The frontend is a web application that allows users to interact with the system, while the backend is responsible for managing the data flow and the communication with the model nodes.

The frontend is built using HTML, CSS, and JavaScript, and provides a user-friendly interface for managing the models and the data. It allows users to start and stop the models, view the health status of the models, and visualize the results of the anomaly detection.

The backend is built using Node.js, which is a JavaScript runtime that allows to run JavaScript code on the server side.

Communication between the frontend and the backend is done throw \texttt{Socket.io}, which is a library that allows real-time communication between the client and the server. This allows the frontend to receive updates from the backend in real-time, such as the health status of the models or the results of the anomaly detection.

\subsection{Frontend}

The frontend main page is shown in \autoref{fig:frontend-main}. There are two main panels: the top panel shows the available models, and the bottom panel consists on four tabs: \textit{Prediction}, \textit{Training}, \textit{History}, and \textit{Preview}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{frontend-principal.png}
    \caption{Frontend main page}
    \label{fig:frontend-main}
\end{figure}

The backend is responsible for sending the model status to the frontend, including the health status, the training status and the prediction results, while the frontend is responsible of displaying this information to the user and sending the backend the user actions, such as adding or removing models, enabling or disabling models, changing model endpoints, starting a training, or making a prediction.

Model configuration is done through the \textit{Configure} button, which opens a modal where the user can change the model's endpoints. This modal is shown in \autoref{fig:frontend-configure}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{model-configuration-modal.png}
    \caption{Model configuration modal}
    \label{fig:frontend-configure}
\end{figure}

\subsubsection{Prediction Tab}

The prediction tab allows users to make predictions using the available models. It provides a simple interface where users can choose the discharge to analyze. The \autoref{fig:frontend-prediction} shows the prediction tab and the result of a prediction.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{frontend-prediction.png}
    \caption{Frontend prediction tab}
    \label{fig:frontend-prediction}
\end{figure}

To ease models comparison, prediction orders can be automatically sent for discharges on a folder. As the Outlier Protocol specifies, models must report prediction per window, and add a justification. But models can differ in how do they calculate the final result. For example, as explained on \autoref{sec:models}, SVM calculates the distance to the separation hyperplane, and it is considered disruption if this value is positive, while XGBoost calculates a probability for being disruptive, so a value between 0 and 1 is returned. For this reason, user can set a threshold for a model, which is the first justification value that will be considered disruptive. Also, a \textit{count threshold} can be specified, this is, the number of consecutive windows that need to be labeled as disruptive to consider that discharge as disruptive. This behavior is represented on \autoref{fig:auto-pred}. The modal enables these personalization options for every online model. 

The frontend excludes the unwanted files and fetches the backend's \texttt{/api/ automated-predicts/session} endpoint, which handles user's information. On the backend section there is a detailed explanation of the implementation.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{frontend-automated-predicts.png}
    \caption{Automated predictions}
    \label{fig:auto-pred}
\end{figure}

\subsubsection{Training Tab}

The training tab (\autoref{fig:frontend-training}) is similar to the prediction tab, but users shall select more than one discharge to train the models. For simplicity, there is a button that allow to add multiple discharges at once, opening a modal that allows to select multiple input files, group them using a custom regular expression, and exclude some files with another regular expression. This modal is shown in \autoref{fig:frontend-add-multiple-discharge}. Discharges can also be labeled as disruptive or non-disruptive by setting a disruption time.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{frontend-train.png}
    \caption{Frontend training tab}
    \label{fig:frontend-training}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{multiple-discharge-modal.png}
    \caption{Add multiple discharges modal}
    \label{fig:frontend-add-multiple-discharge}
\end{figure}

\subsection{Backend}

The orchestrator's backend implementation is complex, as has to handle every possible message from the models. 

The orchestrator backend has three main components: the controller, the middleware and the services. 

The controller is a high-level class that stores model-related information, such as the current alive models, the prediction output, or the training process. It has advanced features for being efficient in memory usage, as queues to store just the necessary files while training. This feature is explained below.

The middleware is a group of utilities to validate input and output information. When the controller sends an order to the models, middleware ensures that information is well-formed to ensure compatibility. It also works on the other way, as model's messages are validated throw the middleware. This component guarantees that if an error occurs, it does not propagate and leads to undefined behavior.

The services component implements the low-level functionality that controller needs to communicate with the models, and exposes a high-level API that controller uses. This component includes the implementation of the voting mechanism, the batching feature to optimize memory usage or the training responses of models.

\subsubsection{Queuing and memory optimization}

The orchestrator is designed to handle multiple models and discharges simultaneously. As a training set can be large (thousands of discharges, each with thousands of windows), the orchestrator does not load every discharge into memory at once. Instead, one queue per model is created, where discharges are stored if needed, freeing memory when possible. The flow is as follows:

\begin{enumerate}
    \item User uploads training files in the dashboard interface through file input or drag-and-drop
    \item Frontend batches files into groups of 10 discharges to avoid overwhelming the server
    \item Frontend creates metadata containing total discharge count and batch discharge information
    \item Frontend sends an HTTP POST request to backend's \texttt{/api/train/raw} endpoint with the batch
    \item Controller receives batch and parses metadata to extract discharge information and file mappings
    \item Controller checks for existing training session or creates new one if none exists
    \item Controller starts a training session, which contacts all enabled models to initialize training
    \item Models respond with acceptance and each gets assigned a queue structure with sequence tracking
    \item Training session object is created with total discharge count, model queues, and processed discharge tracking
    \item Controller processes the current batch of discharges
    \item Service creates lazy stream generator that processes one discharge at a time from the batch
    \item Generator parses sensor files for each discharge individually, not loading all at once
    \item Each processed discharge added to all model queues simultaneously for parallel processing
    \item Discharge memory immediately released after being cloned to all model queues
    \item Asynchronous queue processors start for each model independently and concurrently
    \item Each model's queue processor sends discharges sequentially to that model's training endpoint
    \item Discharge memory released again after successful transmission to each model
    \item Queue processor continues until its queue is empty, then becomes idle
    \item Process repeats for each batch until all discharges sent
    \item Training session monitors progress and automatically finishes when total discharge count reached
    \item All queues emptied and training session cleaned up
    \item Models complete training and send completion notifications back to orchestrator.
\end{enumerate}


\subsubsection{Automated predicts and report generation}

As explained on the frontend section, to facilitate the prediction process, the orchestrator has a built-in feature that allows automatic predictions. This feature loads a directory and makes sequential predictions for each discharge. Orchestrator groups the files by a regular expression, and sends the discharges to the models one by one. Then, orchestrator stores the results and builds a report with statistical data. These results include raw outputs (prediction output per discharge), and a CSV grouping individual window predictions. Results are explained in \autoref{sec:cap4}.

\section{Outlier Models}\label{sec:models}

Every model node shall implement the outlier protocol in order to communicate with the orchestrator. This means that every model is a microservice implementing a server that exposes the necessary endpoints to the orchestrator. The models can be implemented in any programming language, as long as they can handle HTTP requests and responses. Models in this project are implemented in Python and Rust.

For compatibility reasons, every model must split discharges in windows of a fixed length (16 points per window). Models are allowed to extract any relevant data from the windows set.

\subsection{Supervised Binary Classification}

\subsubsection{\acs{SVM}: A Rust implementation of the \acs{APODIS} algorithm}

This project implements the \ac{APODIS} algorithm for anomaly detection as a starting comparison point. The model is implemented in pure Rust, implementing the outlier protocol using the \texttt{actix\_server} framework for the communication with the orchestrator's backend, and the \texttt{linfa} crate for the \ac{SVM} implementation.

The feature extraction logic is implemented in the \texttt{get\_features} function, which extracts the mean and the standard deviation of the FFT magnitudes for each window. This function is shown in \autoref{lst:svm-features}.

\begin{lstlisting}[language=Rust, caption={Feature extraction for the \ac{SVM} model}, label={lst:svm-features}]
    fn get_features(
        &self, 
        window_size: usize
    ) -> (SignalFeatures, SignalFeatures) {
        let num_windows = self.values.len() / window_size;

        let mut mean_values = Vec::with_capacity(num_windows);
        let mut fft_std_values = Vec::with_capacity(num_windows);

        let mut planner = FftPlanner::new();
        let fft = planner.plan_fft_forward(window_size);

        for k in 0..num_windows {
            let start_idx = k * window_size;
            let end_idx = (k + 1) * window_size;
            let window = &self.values[start_idx..end_idx];

            let mean_value = window.iter().sum::<f64>() / window_size as f64;
            mean_values.push(mean_value);

            let mut fft_input: Vec<Complex<f64>> =
                window.iter().map(|&x| Complex::new(x, 0.0)).collect();

            fft.process(&mut fft_input);

            // Positive freqs (without DC component)
            // Only need up to window_size/2 due to symmetry
            let magnitudes: Vec<f64> = fft_input[1..=window_size / 2]
                .iter()
                .map(|c| c.norm())
                .collect();

            // std deviation of FFT magnitudes
            let fft_mean = magnitudes.iter().sum::<f64>() / magnitudes.len() as f64;
            let fft_variance = magnitudes
                .iter()
                .map(|&m| (m - fft_mean) * (m - fft_mean))
                .sum::<f64>() / magnitudes.len() as f64;

            let fft_std = fft_variance.sqrt();
            fft_std_values.push(fft_std);
        }

        (
            SignalFeatures {
                type_: FeatureType::Mean,
                values: mean_values,
            },
            SignalFeatures {
                type_: FeatureType::FftStd,
                values: fft_std_values,
            },
        )
    }
\end{lstlisting}

To train the model, SVM uses the \texttt{linfa} crate, which provides a high-level API for machine learning in Rust. The training process is done with the configuration which is shown in \autoref{lst:svm-train}. This function takes a dataset of features and labels, and trains the model using the \ac{SVM} algorithm with a Gaussian kernel.

\begin{lstlisting}[language=Rust, caption={Training the \ac{SVM} model}, label={lst:svm-train}]
    let model: Svm<f64, bool> = Svm::<f64, bool>::params()
        .gaussian_kernel(10.)
        .pos_neg_weights(1.0, 1.0)
        .fit(&dataset)
        .expect("Error training SVM model");
\end{lstlisting}

The prediction process is done for each window, and the model returns a boolean value indicating whether the window is anomalous or not. The prediction process is shown in \autoref{lst:svm-predict}. The model also returns the distance to the separation hyperplane, which is used to calculate the justification value.

\begin{lstlisting}[language=Rust, caption={Prediction with the \ac{SVM} model}, label={lst:svm-predict}]
    for (i, signal) in dataset
        .records
        .axis_iter(ndarray::Axis(0))
        .enumerate() 
    {
        let distance = model
            .as_ref()
            .unwrap()
            .weighted_sum(&signal.to_owned()) - model.as_ref().unwrap().rho;
        window_props.push(WindowProperties {
            feature_values: signal.to_vec(),
            prediction: if predictions[i] { 
                "Anomaly".to_string() 
                } else { "Normal".to_string() },
            distance,
        });
    }
\end{lstlisting}

\subsubsection{XGBoost}\label{subsubsec:xgboost}

The XGBoost model is implemented in Python, using the \texttt{xgboost} library for the model, and the \texttt{fastapi} framework for the API.\ It is a supervised binary classification model that uses different features extracted from the discharges. These features include basic statics, like the mean and the mean of the slope of each window, the log of the \ac{RMS}, and dynamic features, like the maximum slope, and data related to the second derivative of each window (minimum, maximum and mean). In total, the model uses 7 features extracted from the discharge data for each window.

Model is also fed with the past features of the discharge, that are used as a tendency to give the model more context about the discharge. This means that the model needs a minimum number of windows to be able to make predictions, which is set to 3 windows by default. As past features are treated like the current features, the model uses a total of 28 features (7 features per window, and 4 windows). 

Feature extraction logic for the current window is implemented in the \texttt{extract\_ features} function, which is shown in \autoref{lst:xgboost-features}. This function takes a list of floats as input, which represents the discharge data for a window, and returns a numpy array with the extracted features. The function raises a \texttt{ValueError} if the input window is empty.\ \autoref{lst:xgboost-past-features} shows the feature extraction for the past windows, which is done by iterating over the past windows and extracting the features for each one. The features are then averaged to get a single feature vector for each past window.

\begin{lstlisting}[language=Python, caption={XGBoost feature extraction for the current window}, label={lst:xgboost-features}]
def extract_features(window: list[float]) -> np.ndarray:
    """Extract features from discharge data for model training/prediction"""

    if len(window) == 0:
        raise ValueError("Window cannot be empty")

    features = []

    mean = np.mean(window)
    if len(window) > 1:
        diff = np.diff(window)
    else:
        diff = np.array([0.0])

    if len(window) > 2:
        abs_second_derivate = np.abs(np.diff(diff))
    else:
        abs_second_derivate = np.array([0.0])

    features.extend([
        # Core statistics
        mean,
        diff.mean() * 1/SAMPLING_TIME, # Slope (mean of diffs) 
        np.log1p(np.sqrt(np.mean(np.square(window)))), # log of RMS

        # Dynamic features
        np.max(np.abs(diff)), # Max slope
        # Second derivative features
        np.min(abs_second_derivate) * 1/(SAMPLING_TIME**2),
        np.max(abs_second_derivate) * 1/(SAMPLING_TIME**2),
        np.mean(abs_second_derivate) * 1/(SAMPLING_TIME**2),
    ])
    return np.array(features).reshape(1, -1)
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={XGBoost feature extraction for the past windows}, label={lst:xgboost-past-features}]
    for j in range(1, num_tendency + 1):
        prev_idx = window_idx - j
        if prev_idx in aligned_windows and len(aligned_windows[prev_idx]) > 0:
            prev_window_features = np.zeros(feature_size)
            for window in aligned_windows[prev_idx]:
                prev_window_features += extract_features(window)[0]
            prev_window_features /= len(aligned_windows[prev_idx])
            all_features.append(prev_window_features)
\end{lstlisting}

The necessary parameters to create an XGBoost model with the \texttt{xgboost} library are shown on \autoref{lst:xgboost-params}. These parameters are set to values that have been tested and work well for the project, but they can be modified to improve the model's performance. The \texttt{tree\_method} is set to \texttt{hist} to use a histogram-based algorithm, which is faster and more memory-efficient than the default \texttt{exact} method\todo{Ref}. The \texttt{n\_jobs} parameter is set to -1 to use all available CPU cores for training. The \texttt{objective} is set to \texttt{binary:logistic} for binary classification, and the evaluation metric is set to \texttt{aucpr} (area under the precision-recall curve) for better performance in imbalanced datasets, like the given ones.

\begin{lstlisting}[language=Python, caption={XGBoost model parameters}, label={lst:xgboost-params}]
    params = {
        # Algorithm and hardware settings
        'tree_method': 'hist',
        'n_jobs': -1,
        # Objective and evaluation metrics
        'objective': 'binary:logistic',
        'eval_metric': 'aucpr',
        # Regularization and overfitting control
        'learning_rate': 0.05,
        'scale_pos_weight': scale_pos_weight,
        # Hyperparameters
        'max_depth': 6,
        'min_child_weight': 3,
        'gamma': 1.0,
        'eta': 0.02,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
    }

    dtrain = xgb.DMatrix(X_array, label=y_array)
    model = xgb.train(params, 
                      dtrain, 
                      num_boost_round=10000, 
                      verbose_eval=10
                      )

\end{lstlisting}

XGBoost predicts the probability of a window being disruptive, so a post-processing step is needed to determine if the discharge is disruptive or not. This post-processing step is done by the orchestrator, setting a threshold, which is set to 0.5 by default (50\% chance of being disruptive), and a number of consecutive windows that must be disruptive to consider the discharge as disruptive, which is set to 3 by default. This means that if 3 consecutive windows are above the threshold, the discharge is considered disruptive.

It is important to note that the XGBoost uses \texttt{scale\_pos\_weight} parameter to balance the classes. This means that the model is trained to give more importance to the disruptive class, as it is the minority class in the dataset. This parameter sets the weight of the positive class (disruptive) to the ratio of negative to positive samples, which is calculated as 

\begin{equation}
    w_i = \frac{N_{neg}}{N_{pos}}
    \label{eq:scale_pos_weight}
\end{equation}

This helps the model to learn better from the minority class and improve its performance. This value is approximately 11 for the C23 campaign, as there are 11 non-disruptive windows for each disruptive window.

\subsubsection{CNN-FFT}

\subsection{Outlier Detection}

This section explains outlier detection models that are implemented for the project. These models are only trained with non-disruptive discharges, and try to find common patterns between them. If a window differs more than a threshold from the pattern, it is labeled as disruptive.

\subsubsection{\acs{OC-SVM}}

\subsubsection{Isolation Forest}

The \ac{IForest} model is implemented in Python, using \texttt{sklearn} library for the model, and the \texttt{fastapi} framework for the API.\ As \texttt{sklearn} is used, if a \ac{GPU} is available, it will be used to improve training times.

This model extracts some relevant features from windows, which include statistical data (mean value, standard deviation, minimum, maximum and range)

\subsubsection{\acs{LSTM}}

