@inproceedings{10.1007/978-3-540-30115-8_7,
  title = {Applying Support Vector Machines to Imbalanced Datasets},
  booktitle = {Machine Learning: {{ECML}} 2004},
  author = {Akbani, Rehan and Kwek, Stephen and Japkowicz, Nathalie},
  editor = {Boulicaut, Jean-François and Esposito, Floriana and Giannotti, Fosca and Pedreschi, Dino},
  date = {2004},
  pages = {39--50},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  abstract = {Support Vector Machines (SVM) have been extensively studied and have shown remarkable success in many applications. However the success of SVM is very limited when it is applied to the problem of learning from imbalanced datasets in which negative instances heavily outnumber the positive instances (e.g. in gene profiling and detecting credit card fraud). This paper discusses the factors behind this failure and explains why the common strategy of undersampling the training data may not be the best choice for SVM. We then propose an algorithm for overcoming these problems which is based on a variant of the SMOTE algorithm by Chawla et al, combined with Veropoulos et al's different error costs algorithm. We compare the performance of our algorithm against these two algorithms, along with undersampling and regular SVM and show that our algorithm outperforms all of them.},
  isbn = {978-3-540-30115-8}
}

@article{1522531,
  title = {Top-down Induction of Decision Trees Classifiers - a Survey},
  author = {Rokach, L. and Maimon, O.},
  date = {2005},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume = {35},
  number = {4},
  pages = {476--487},
  doi = {10.1109/TSMCC.2004.843247},
  keywords = {Classification,Classification tree analysis,Data mining,decision trees,Decision trees,Industrial training,Loans and mortgages,Machine learning,Machine learning algorithms,Pattern recognition,Predictive models,pruning methods,splitting criteria,Statistics}
}

@article{354051491,
  title = {A Reliable Network Intrusion Detection Approach Using Decision Tree with Enhanced Data Quality},
  author = {Guezzaz, Azidine and Benkirane, Said and Azrour, Mourade and Khurram, Shahzada},
  date = {2021-08},
  journaltitle = {Security and Communication Networks},
  volume = {2021},
  doi = {10.1155/2021/1230593}
}

@inproceedings{6524743,
  title = {{{SVM}} Kernel Functions for Classification},
  booktitle = {2013 International Conference on Advances in Technology and Engineering ({{ICATE}})},
  author = {Patle, Arti and Chouhan, Deepak Singh},
  date = {2013},
  pages = {1--9},
  doi = {10.1109/ICAdTE.2013.6524743},
  keywords = {Accuracy,Data mining,feature,Kernel,Mathematical model,Polynomials,radial basis function,support vector,Support vector machines,Training}
}

@article{binary-classification-for-fraud-detection,
  title = {Investigating the Effectiveness of One-Class and Binary Classification for Fraud Detection},
  author = {Leevy, Joffrey and Hancock, John and Khoshgoftaar, Taghi and Abdollah Zadeh, Azadeh},
  date = {2023-10},
  journaltitle = {Journal of Big Data},
  volume = {10},
  doi = {10.1186/s40537-023-00825-1}
}

@book{chenXGBoostScalableTree2016,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  date = {2016-08-13},
  pages = {794},
  doi = {10.1145/2939672.2939785},
  pagetotal = {785}
}

@article{friedmanGreedyFunctionApproximation2000,
  title = {Greedy {{Function Approximation}}: {{A Gradient Boosting Machine}}},
  author = {Friedman, Jerome},
  date = {2000-11-28},
  journaltitle = {The Annals of Statistics},
  volume = {29},
  doi = {10.1214/aos/1013203451}
}

@article{haririExtendedIsolationForest2019,
  title = {Extended {{Isolation Forest}} with {{Randomly Oriented Hyperplanes}}},
  author = {Hariri, Sahand and Kind, Matias and Brunner, Robert},
  date = {2019-10-31},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {PP},
  pages = {1--1},
  doi = {10.1109/TKDE.2019.2947676},
  abstract = {We present an extension to the model-free anomaly detection algorithm, Isolation Forest. This extension, named Extended Isolation Forest (EIF), resolves issues with assignment of anomaly score to given data points. We motivate the problem using heat maps for anomaly scores. These maps suffer from artifacts generated by the criteria for branching operation of the binary tree. We explain this problem in detail and demonstrate the mechanism by which it occurs visually. We then propose two different approaches for improving the situation. First we propose transforming the data randomly before creation of each tree, which results in averaging out the bias. Second, which is the preferred way, is to allow the slicing of the data to use hyperplanes with random slopes. This approach results in remedying the artifact seen in the anomaly score heat maps. We show that the robustness of the algorithm is much improved using this method by looking at the variance of scores of data points distributed along constant level sets. We report AUROC and AUPRC for our synthetic datasets, along with real-world benchmark datasets. We find no appreciable difference in the rate of convergence nor in computation time between the standard Isolation Forest and EIF.}
}

@inproceedings{inproceedings,
  title = {Isolation Forest},
  author = {Liu, Fei Tony and Ting, Kai and Zhou, Zhi-Hua},
  date = {2009-01},
  pages = {413--422},
  doi = {10.1109/ICDM.2008.17}
}

@online{kekulawalaSupportVectorMachines2024,
  title = {Support {{Vector Machines}}: {{A}} Mathematical Guide — {{Part}} 3},
  shorttitle = {Support {{Vector Machines}}},
  author = {Kekulawala, Chamuditha},
  date = {2024-06-11T09:02:32},
  url = {https://medium.com/@ckekula/support-vector-machines-a-mathematical-guide-part-3-78fd3c8bf44c},
  urldate = {2025-07-12},
  abstract = {In part 2 we talked about adding similarity features using the Gaussian RBF function. Now let’s go into the RBF Kernel trick.},
  langid = {english},
  organization = {Medium},
  file = {/home/ruben/snap/zotero-snap/common/Zotero/storage/5GZVFU77/support-vector-machines-a-mathematical-guide-part-3-78fd3c8bf44c.html}
}

@software{OutlierClassifierOutlier_orchestrator2025,
  title = {{{outlierClassifier}}/Outlier\_orchestrator},
  date = {2025-08-06T22:32:44Z},
  origdate = {2025-04-26T15:18:40Z},
  url = {https://github.com/outlierClassifier/outlier_orchestrator},
  urldate = {2025-08-13},
  abstract = {Orquestador de modelos para detección de anomalías},
  organization = {outlierClassifier}
}

@software{OutlierClassifierPy_xgboost2025,
  title = {{{outlierClassifier}}/Py\_xgboost},
  date = {2025-08-03T08:12:39Z},
  origdate = {2025-04-29T11:54:35Z},
  url = {https://github.com/outlierClassifier/py_xgboost},
  urldate = {2025-08-12},
  abstract = {py\_xgboost},
  organization = {outlierClassifier}
}
